{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install python3-h5py python3-numpy\n",
    "!pip3 install protobuf==3.19.6\n",
    "!wget https://developer.download.nvidia.com/compute/redist/jp/v461/tensorflow/tensorflow-2.7.0+nv22.1-cp36-cp36m-linux_aarch64.whl\n",
    "!pip3 install tensorflow-2.7.0+nv22.1-cp36-cp36m-linux_aarch64.whl\n",
    "!pip3 install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "qvVSHQfbEPkm",
    "outputId": "91d0a05c-a4e7-4b36-9a19-c0599c654087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max value in image:  0 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max value in image:  0.0 1.0\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper functions\n",
    "def show_min_max(array, i):\n",
    "  random_image = array[i]\n",
    "  print(\"min and max value in image: \", random_image.min(), random_image.max())\n",
    "\n",
    "\n",
    "def plot_image(array, i, labels):\n",
    "  plt.imshow(np.squeeze(array[i]))\n",
    "  plt.title(\" Digit \" + str(labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28  \n",
    "\n",
    "num_classes = 10 \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data() \n",
    "\n",
    "\n",
    "print(train_images.shape) \n",
    "print(test_images.shape) \n",
    "\n",
    "if K.image_data_format() == 'channels_first': \n",
    "  train_images = train_images.reshape(train_images.shape[0], 1, img_rows, img_cols)\n",
    "  test_images = test_images.reshape(test_images.shape[0], 1, img_rows, img_cols)\n",
    "  input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "else:\n",
    "  train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "  test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "  input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "plot_image(train_images, 100, train_labels)\n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "\n",
    "plot_image(train_images, 4563, train_labels)\n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(train_images[1232].shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
